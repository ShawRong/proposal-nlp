\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}

\title{SemEval-2025 Task-3 — Mu-SHROOM}
\author{}
\date{}

\begin{document}

\maketitle

\section{Introduction}

This task is part of SemEval-2025 Task-3 — Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. This iteration builds on the previous SHROOM task with key \textbf{changes}:

\begin{itemize}
    \item \textbf{Multilingual Focus}: The task covers multiple languages, including Arabic (Modern Standard), Chinese (Mandarin), English, Finnish, French, German, Hindi, Italian, Spanish, and Swedish.
    \item \textbf{LLM Outputs}: The emphasis is on detecting hallucinations in outputs from instruction-tuned language models (LLMs).
    \item \textbf{Hallucination Detection}: Participants will predict the locations of hallucinations within the generated text.
\end{itemize}
%PUT THEM INTO A SENTENCE, NOT SEPARATED!

Mu-SHROOM focuses on identifying spans of text that represent hallucinations in LLM outputs, working within a multilingual and multi-model context. More information is available on the \href{https://helsinki-nlp.github.io/shroom/}{official task website}.

\section{Dataset Details}

The datasets provided include a sample set, validation set, and unlabeled train set. Each data point is formatted as a JSON object containing:

\begin{itemize}
    \item A unique identifier (\texttt{id})
    \item Language (\texttt{lang})
    \item Model input question (\texttt{model\_input})
    \item Model identifier (\texttt{model\_id})
    \item Generated output (\texttt{model\_output\_text})
    \item Hard labels (binarized annotations) indicating hallucination spans
    \item Soft labels (continuous annotations) with start, end, and empirical probability of hallucination
\end{itemize}
%THIS PART I WANT THEM TO BE IN A SENTENCE INSTEAD OF MULTI_LINES.

The hard labels will be used to assess intersection-over-union accuracy, while soft labels will measure correlation. Participants will reconstruct soft labels during evaluation by providing the required keys for detected spans.

\subsection{Sample Dataset Illustration}

\begin{verbatim}
{
    "id": 1,
    "lang": "EN",
    "model_input": "When was the restoration of the Sándor Palace completed?",
    "model_output_text": "The restoration of Sándor Palace, also known as the Buda Castle ...",
    "model_id": "TheBloke/Mistral-7B-Instruct-v0.2-GGUF",
    "soft_labels": [
        {
            "start": 33,
            "prob": 0.3333333333,
            "end": 53
        }
    ],
    "hard_labels": [
        [53, 64]
    ]
}
\end{verbatim}
%MAKE THIS CODE CONCISE TO BE IN ONE LINE! FIND OTHER WAY TO ILLUSTRATE THIS CODE!

\section{Tasks}

Participants are tasked with detecting hallucinations in the provided text. 

\subsection{Evaluation Metrics}

Participants will be evaluated based on two character-level metrics:

\begin{enumerate}
    \item \textbf{Intersection-over-Union}: Measures the overlap between characters marked as hallucinations in the gold reference and those predicted by participants.
    \item \textbf{Probability Correlation}: Assesses how well the probabilities assigned by participants align with those observed by annotators.
\end{enumerate}
%NOT ITEM! I NEED THEM TO BE IN ONE LINE!
This is a preliminary overview of our proposal; further refinements will be made as the task develops.

\end{document}

% MAKE THE MARGIN SMALLER! TO MUCH BLANK